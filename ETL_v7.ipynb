{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import openpyxl\n",
    "from math import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract CSVs and Excel Sheets into DataFrames\n",
    "1. Extract game.csv for AFL Game Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_file = \"games.csv\"\n",
    "game_df = pd.read_csv(game_file)\n",
    "game_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extract status.csv for AFL team player's Performance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_file = \"stats.csv\"\n",
    "stats_df = pd.read_csv(stats_file)\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract the sheet1 of AFL_Stadiums.xlsx for Venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_file = \"AFL_Stadiums.xlsx\"\n",
    "venue_df = pd.read_excel(io=venue_file,sheet_name=0,header=3)\n",
    "venue_df.columns=['venue_name', 'in_use', 'games', 'goals', 'behinds', 'points', 'ave_sore', 'over_100']\n",
    "venue_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extract the sheet2 of AFL_Stadiums.xlsx for AFL Stadiums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadium_file = \"AFL_Stadiums.xlsx\"\n",
    "stadium_df = pd.read_excel(io=stadium_file,sheet_name=1,header=2)\n",
    "stadium_df.columns=['name', 'city_name', 'state_name', 'capacity']\n",
    "stadium_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns\n",
    "player_cols = [\"playerId\", \"displayName\"]\n",
    "player_transformed = stats_df[player_cols].copy()\n",
    "\n",
    "# split First name and Last name from full name \n",
    "player_name = player_transformed['displayName'].str.split(',', expand=True)\n",
    "player_transformed['first_name']=player_name[1]\n",
    "player_transformed['last_name']=player_name[0]\n",
    "\n",
    "player_transformed.drop('displayName',axis=1,inplace=True)\n",
    "\n",
    "# Rename the column headers\n",
    "player_transformed = player_transformed.rename(columns={\"playerId\": \"player_id\"})\n",
    "\n",
    "# Clean the data by dropping duplicates and setting the index\n",
    "player_transformed.drop_duplicates(\"player_id\", inplace=True)\n",
    "player_transformed.set_index(\"player_id\", inplace=True)\n",
    "\n",
    "player_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns \"team\"\n",
    "team_transformed = stats_df[\"team\"].copy()\n",
    "team_transformed.drop_duplicates(inplace=True)\n",
    "\n",
    "team_transformed = team_transformed.reset_index()\n",
    "\n",
    "# set auto-increment ID as team_id\n",
    "team_transformed['team_id'] = range(1,len(team_transformed)+1)\n",
    "# Rename the column headers\n",
    "team_transformed.rename(columns = {'team':'team_name'}, inplace = True)\n",
    "# Clean the data by dropping duplicates and setting the index\n",
    "team_transformed.set_index(\"team_id\", inplace=True)\n",
    "team_transformed.drop('index',axis=1,inplace=True)\n",
    "\n",
    "team_transformed.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns\n",
    "city_cols = ['city_name', 'state_name']\n",
    "city_transformed = stadium_df[city_cols].copy()\n",
    "\n",
    "# Clean the data by dropping duplicates and setting the index\n",
    "city_transformed.drop_duplicates(\"city_name\", inplace=True)\n",
    "\n",
    "#set auto-increment ID as city_id\" column with range function by lenth \n",
    "city_transformed['city_id'] = range(1,len(city_transformed)+1)\n",
    "#set index for \"city_id\"\n",
    "city_transformed.set_index(\"city_id\", inplace=True)\n",
    "\n",
    "city_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacae the name for the same stadium with abbreviation\n",
    "stadium_df.replace('Melbourne Cricket Ground','M.C.G.', inplace=True)\n",
    "stadium_df.replace('Sydney Cricket Ground','S.C.G.', inplace=True)\n",
    "stadium_df.replace('Jiangwan Stadium (CHN)','Jiangwan Stadium', inplace=True)\n",
    "\n",
    "#get unique names with unique function and union with the stadium name in stadium df and venue df in the same list\n",
    "stadium_name = set(game_df[\"venue\"].unique().tolist()).union(set(stadium_df['name'].unique().tolist())).union(set(venue_df['venue_name'].unique().tolist()))\n",
    "\n",
    "stadium_name = pd.DataFrame(list(stadium_name),columns=['name'])\n",
    "stadium_name['stadium_id'] = range(1,len(stadium_name)+1)\n",
    "\n",
    "\n",
    "venue_cols = ['venue_name', 'in_use']\n",
    "venue = venue_df[venue_cols].copy()\n",
    "venue.rename(columns = {'venue_name':'name'}, inplace = True)\n",
    "\n",
    "# split the in_use data into start year data as int and end year data as int\n",
    "venue['start_year'] = venue['in_use'].astype(str).str[0:4].astype(int)\n",
    "venue['end_year'] = venue['in_use'].astype(str).str[-4:].astype(int)\n",
    "\n",
    "#left join with dataframe 'stadium_name'\n",
    "venue = pd.merge(stadium_name, venue, on='name', how='left')\n",
    "# venue.fillna(0, inplace=True)\n",
    "venue.sort_values('end_year', ascending=False, inplace=True)\n",
    "\n",
    "venue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadium_transformed = pd.merge(stadium_df, venue, on='name', how='outer')\n",
    "\n",
    "\n",
    "# to connect same \"city_name\" in city_transformed and \"stadium_transformed\" to get the city_id \n",
    "\n",
    "def get_city_id(x):\n",
    "    city_rows = city_transformed.loc[city_transformed['city_name'] == x]\n",
    "    if len(city_rows)>0: # if the len greater than 0 , return the index as the city_id\n",
    "        return city_rows.index.values[0]\n",
    "    else:\n",
    "        return ''\n",
    "stadium_transformed['city_id'] = stadium_transformed['city_name'].map(get_city_id)\n",
    "\n",
    "#  set criteria as if \"end_year\" is < 2022,return the boolean value true or false the stadium is active\n",
    "\n",
    "def is_stadium_active(x):\n",
    "    if x < 2022:\n",
    "        return False\n",
    "    elif isnan(x):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "stadium_transformed['active_ind'] = stadium_transformed['end_year'].map(is_stadium_active)#use map to link active_ind back to the end_year list from stadium_transformed\n",
    "\n",
    "\n",
    "stadium_transformed = stadium_transformed[['stadium_id', 'name', 'city_id', 'start_year', 'end_year', 'capacity', 'active_ind']]\n",
    "\n",
    "#drop the duplicates and set the index\n",
    "stadium_transformed.drop_duplicates(\"stadium_id\", inplace=True)\n",
    "stadium_transformed.set_index(\"stadium_id\", inplace=True)\n",
    "stadium_transformed.sort_values(by=['end_year', 'city_id'], ascending=[False, True], inplace=True)\n",
    "stadium_transformed.dropna(inplace=True)\n",
    "stadium_transformed.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe from specific columns\n",
    "stats_cols = [\"gameId\", \"team\", \"playerId\", \"Rebounds\",\"Inside 50s\",\"Clearances\",\"Contested Possessions\"]\n",
    "stats_transformed = stats_df[stats_df['year'] >= 2018][stats_cols].copy()\n",
    "\n",
    "# Rename the column headers\n",
    "stats_transformed = stats_transformed.rename(columns={\"gameId\": \"game_id\",\n",
    "                                                        \"playerId\": \"player_id\",\n",
    "                                                        \"Rebounds\": \"rebound\",\n",
    "                                                        \"Clearances\": \"clearance\",\n",
    "                                                        \"Inside 50s\": \"inside_50s\",\n",
    "                                                        \"Contested Possessions\": \"contested_possessions\",\n",
    "                                                     })\n",
    "# by loc function, to find the 'team_name' from team_transformed df and find its lenth of row and set the index as team_id\n",
    "def get_team_id(x):\n",
    "    team_rows = team_transformed.loc[team_transformed['team_name'] == x]\n",
    "    if len(team_rows)>0:\n",
    "        return team_rows.index.values[0]\n",
    "    else:\n",
    "        return ''\n",
    "stats_transformed['team_id'] = stats_transformed['team'].map(get_team_id)\n",
    "\n",
    "#set the performance criteria for each player adding sum of key criterias: rebounds, inside_50s, clearance, contested possessions\n",
    "stats_transformed['performance'] = stats_transformed[[\"rebound\",\"inside_50s\",\"clearance\",\"contested_possessions\"]].sum(axis=1)\n",
    "\n",
    "stats_transformed.drop('team', axis=1, inplace=True)\n",
    "# Clean the data by dropping duplicates and setting the index\n",
    "stats_transformed.drop_duplicates(\"game_id\", inplace=True)\n",
    "stats_transformed.set_index(\"game_id\", inplace=True)\n",
    "\n",
    "stats_transformed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the data from dataframe above 2018 as latest data, we skip data of 2021&2022 due to data incomplete in covid19 \n",
    "game_transformed = game_df[game_df['year'] >= 2018]\n",
    "\n",
    "# Rename the column headers\n",
    "game_transformed = game_transformed.rename(columns={\"gameId\": \"game_id\",\n",
    "                                                        \"startTime\": \"start_time\",\n",
    "                                                        \"homeTeamScore\": \"home_team_score\",\n",
    "                                                        \"awayTeamScore\": \"away_team_score\",\n",
    "                                                        \"rainfall\": \"rain_fall\"\n",
    "                                                     })\n",
    "#use 'homeTeam' to map to connect with 'home_team_id'\n",
    "game_transformed['home_team_id'] = game_transformed['homeTeam'].map(get_team_id)\n",
    "game_transformed['away_team_id'] = game_transformed['awayTeam'].map(get_team_id)\n",
    "game_transformed.drop('homeTeam', axis=1, inplace=True)\n",
    "game_transformed.drop('awayTeam', axis=1, inplace=True)\n",
    "\n",
    "#left merge the game_transformend df with the venue\n",
    "game_transformed = pd.merge(game_transformed, venue, left_on='venue', right_on='name', how='left')\n",
    "game_transformed.drop('venue', axis=1, inplace=True)\n",
    "game_transformed.drop('start_year', axis=1, inplace=True)\n",
    "game_transformed.drop('end_year', axis=1, inplace=True)\n",
    "game_transformed.drop('in_use', axis=1, inplace=True)\n",
    "\n",
    "#str type transfer to date type\n",
    "game_transformed['date'] = pd.to_datetime(game_transformed['date'], format='%d-%b-%Y')\n",
    "# str type transfered to 24-hr time type\n",
    "game_transformed['start_time'] = pd.to_datetime(game_transformed['start_time']).dt.strftime('%H:%M')\n",
    "# drop the duplicates and set index\n",
    "game_transformed.drop_duplicates(\"game_id\", inplace=True)\n",
    "game_transformed.set_index(\"game_id\", inplace=True)\n",
    "\n",
    "\n",
    "game_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TVS_df =pd.read_csv(stats_file)\n",
    "df1=TVS_df\n",
    "df1_2=df1.query(\"year == 2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1_2.groupby(['team'])['Rebounds','Inside 50s','Clearances','Contested Possessions'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.sum(axis = 1)\n",
    "df4=pd.DataFrame(df3)\n",
    "df4.columns=['TVS']\n",
    "\n",
    "\n",
    "TVS_transformed=df4.sort_values(['TVS'],ascending=False)\n",
    "TVS_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_transformed.to_csv('output/player_transformed_result.csv',index=0)\n",
    "stadium_transformed.to_csv('output/stadium_transformed_result.csv',index=0)\n",
    "city_transformed.to_csv('output/city_transformed_result.csv',index=0)\n",
    "team_transformed.to_csv('output/team_transformed_result.csv',index=0)\n",
    "game_transformed.to_csv('output/game_transformed_result.csv',index=0)\n",
    "stats_transformed.to_csv('output/stats_transformed_result.csv',index=0)\n",
    "TVS_transformed.to_csv('output/stats_transformed_result.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsd_connection_string = \"postgres:Claudia@localhost:5432/AFLGame_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f'postgresql://{rsd_connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"postgres:Claudia@localhost:5432/AFLGame_db\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_transformed.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_transformed.to_sql('player', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadium_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadium_transformed.reset_index(inplace = True)\n",
    "stadium_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadium_transformed.to_sql('stadium', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_transformed.reset_index(inplace = True)\n",
    "city_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_transformed.to_sql('city', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_transformed.reset_index(inplace = True)\n",
    "team_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_transformed.to_sql('team', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_transformed.reset_index(inplace = True)\n",
    "game_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_transformed.to_sql('game', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_transformed.reset_index(inplace = True)\n",
    "stats_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_transformed.to_sql('stats', engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc63edf58eb46c968fb7d3ccda5a34293e52b04a864a54af3a79f22bef64bf93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
